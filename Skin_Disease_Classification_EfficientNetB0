{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6695743,"sourceType":"datasetVersion","datasetId":3860205}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflowjs\n!pip install TensorFlow==2.15.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-07T22:28:02.688639Z","iopub.execute_input":"2024-06-07T22:28:02.688919Z","iopub.status.idle":"2024-06-07T22:28:34.826424Z","shell.execute_reply.started":"2024-06-07T22:28:02.688893Z","shell.execute_reply":"2024-06-07T22:28:34.825391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import MobileNet,EfficientNetB0, InceptionV3,ResNet50\nfrom tensorflow.keras.layers import GlobalMaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score,recall_score, f1_score\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:43:05.707035Z","iopub.execute_input":"2024-06-07T22:43:05.707897Z","iopub.status.idle":"2024-06-07T22:43:05.715289Z","shell.execute_reply.started":"2024-06-07T22:43:05.707861Z","shell.execute_reply":"2024-06-07T22:43:05.714380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"train_val_path = '/kaggle/input/skin-disease-dataset/skin-disease-datasaet/train_set'\ntest_path = '/kaggle/input/skin-disease-dataset/skin-disease-datasaet/test_set'\n\ndatagen = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    brightness_range=[0.8, 1.2],\n    fill_mode='reflect'\n)\n\ntrain_data = []\nval_data = []\n\ntrain_class_counts = {}\nval_class_counts ={}\n\nfor folder in sorted(os.listdir(train_val_path)):\n    folder_path = os.path.join(train_val_path, folder)\n    file = os.listdir(folder_path)\n    num_train = int(0.8 * len(file))\n    files_train = random.sample(file, num_train)\n    files_val = list(set(file) - set(files_train))\n    \n    train_class_counts[folder] = 0\n    val_class_counts[folder] = 0\n    \n    for file in files_train:\n        file_path = os.path.join(folder_path, file)\n        img = cv2.imread(file_path)\n        img = cv2.resize(img, (224, 224)) \n        train_data.append((img, folder))\n\n        img_array = np.expand_dims(img, axis=0)\n\n        for _ in range(2):\n            augmented_img = datagen.flow(img_array).next()[0].astype(np.uint8)\n            train_data.append((augmented_img, folder))\n        \n        train_class_counts[folder] += 3  \n\n    for file in files_val:\n        file_path = os.path.join(folder_path, file)\n        img = cv2.imread(file_path)\n        img = cv2.resize(img, (224, 224))\n        val_data.append((img, folder))\n        \n        val_class_counts[folder] += 1 \n\ntest_data = []\ntest_class_counts = {}\n\nfor folder in sorted(os.listdir(test_path)):\n    folder_path = os.path.join(test_path, folder)\n    files_test = os.listdir(folder_path)\n    test_class_counts[folder] = 0\n    for file in files_test:\n        file_path = os.path.join(folder_path, file)\n        img = cv2.imread(file_path)\n        img = cv2.resize(img, (224, 224)) \n        test_data.append((img, folder))\n        img_array = np.expand_dims(img, axis=0)\n        test_class_counts[folder] += 1  \n    \nfor class_name, count in train_class_counts.items():\n    print(f\"Kelas '{class_name}' dalam data TRAIN {count} gambar.\")\n\nfor class_name, count in val_class_counts.items():\n    print(f\"Kelas '{class_name}' dalam data VALIDASI {count} gambar.\")\n    \nfor class_name, count in test_class_counts.items():\n    print(f\"Kelas '{class_name}' dalam data TEST {count} gambar.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:33:34.214191Z","iopub.execute_input":"2024-06-07T22:33:34.214584Z","iopub.status.idle":"2024-06-07T22:33:53.230253Z","shell.execute_reply.started":"2024-06-07T22:33:34.214556Z","shell.execute_reply":"2024-06-07T22:33:53.229331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nclass_images = {}\n\nfor img, label in train_data:\n    if label not in class_images:\n        class_images[label] = img\n\nfig, axes = plt.subplots(2, 4, figsize=(10, 5))\nplt.suptitle('LABELS OF EACH IMAGE')\n\nfor (label, img), ax in zip(class_images.items(), axes.flatten()):\n    ax.xaxis.set_ticklabels([])\n    ax.yaxis.set_ticklabels([])\n    ax.grid(True)\n    ax.set_title(label)\n    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:33:53.232562Z","iopub.execute_input":"2024-06-07T22:33:53.233189Z","iopub.status.idle":"2024-06-07T22:33:54.368774Z","shell.execute_reply.started":"2024-06-07T22:33:53.233149Z","shell.execute_reply":"2024-06-07T22:33:54.367876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Perancangan Model ","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\nbase_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False\n\nnum_classes = 8\nx = GlobalMaxPooling2D()(base_model.output)\n\nx = Dense(512, activation='relu', kernel_initializer='he_normal')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\n   \npredictions = Dense(num_classes, activation='softmax')(x)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:34:47.671129Z","iopub.execute_input":"2024-06-07T22:34:47.671536Z","iopub.status.idle":"2024-06-07T22:34:50.503962Z","shell.execute_reply.started":"2024-06-07T22:34:47.671489Z","shell.execute_reply":"2024-06-07T22:34:50.502868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=base_model.input, outputs=predictions)\nmodel.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['accuracy'])\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:34:50.506001Z","iopub.execute_input":"2024-06-07T22:34:50.506353Z","iopub.status.idle":"2024-06-07T22:34:51.141653Z","shell.execute_reply.started":"2024-06-07T22:34:50.506325Z","shell.execute_reply":"2024-06-07T22:34:51.140685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\n\nX_train, y_train = zip(*train_data)\nX_val, y_val = zip(*val_data)\n\nX_train = preprocess_input(np.array(X_train))\nX_val = preprocess_input(np.array(X_val))\n\nle = LabelEncoder()\ny_train_encoded = le.fit_transform(y_train)\ny_val_encoded = le.transform(y_val)\n\ny_train_one_hot = to_categorical(y_train_encoded, num_classes)\ny_val_one_hot = to_categorical(y_val_encoded, num_classes)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:34:51.142905Z","iopub.execute_input":"2024-06-07T22:34:51.143230Z","iopub.status.idle":"2024-06-07T22:34:51.632008Z","shell.execute_reply.started":"2024-06-07T22:34:51.143181Z","shell.execute_reply":"2024-06-07T22:34:51.630986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Model","metadata":{}},{"cell_type":"code","source":"EPOCHS = 100\nBATCH_SIZE = 128\n\nbest_model_dir = '/kaggle/working/'\nearly_stopping = EarlyStopping(monitor='val_loss', patience=15)\nmodel_checkpoint = ModelCheckpoint(\n    os.path.join(best_model_dir, 'best_model_EfficientNetB0.h5'),\n    monitor='val_loss', \n    save_best_only=True,\n    mode='min', \n    verbose=1\n)\n\nhistory = model.fit(X_train, y_train_one_hot,\n                    validation_data=(X_val, y_val_one_hot),\n                    epochs=EPOCHS, \n                    batch_size=BATCH_SIZE,\n                    callbacks=[early_stopping, model_checkpoint])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:34:51.633274Z","iopub.execute_input":"2024-06-07T22:34:51.633569Z","iopub.status.idle":"2024-06-07T22:38:41.997287Z","shell.execute_reply.started":"2024-06-07T22:34:51.633542Z","shell.execute_reply":"2024-06-07T22:38:41.996276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(train_loss) + 1)\n\nplt.plot(epochs, train_loss,label='Training loss', marker='o')\nplt.plot(epochs, val_loss,label='Validation loss', marker='o')\nplt.title('Training and Validation Losses')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:38:42.001303Z","iopub.execute_input":"2024-06-07T22:38:42.001702Z","iopub.status.idle":"2024-06-07T22:38:42.272061Z","shell.execute_reply.started":"2024-06-07T22:38:42.001675Z","shell.execute_reply":"2024-06-07T22:38:42.271271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = history.history['accuracy']\nval_loss = history.history['val_accuracy']\n\nepochs = range(1, len(train_loss) + 1)\n\nplt.plot(epochs, train_loss,label='Training accuracy', marker='o')\nplt.plot(epochs, val_loss,label='Validation accuracy', marker='o')\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:38:42.273239Z","iopub.execute_input":"2024-06-07T22:38:42.273576Z","iopub.status.idle":"2024-06-07T22:38:42.623755Z","shell.execute_reply.started":"2024-06-07T22:38:42.273548Z","shell.execute_reply":"2024-06-07T22:38:42.622728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluasi Model","metadata":{}},{"cell_type":"code","source":"test_path = '/kaggle/input/skin-disease-dataset/skin-disease-datasaet/test_set'","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:38:42.625325Z","iopub.execute_input":"2024-06-07T22:38:42.625816Z","iopub.status.idle":"2024-06-07T22:38:42.630817Z","shell.execute_reply.started":"2024-06-07T22:38:42.625777Z","shell.execute_reply":"2024-06-07T22:38:42.629769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('/kaggle/working/best_model_EfficientNetB0.h5') ","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:38:57.210058Z","iopub.execute_input":"2024-06-07T22:38:57.211123Z","iopub.status.idle":"2024-06-07T22:38:59.589821Z","shell.execute_reply.started":"2024-06-07T22:38:57.211085Z","shell.execute_reply":"2024-06-07T22:38:59.588715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_label = []\npredicted_class = []\n\nfor folder in sorted(os.listdir(test_path)):\n    folder_path = os.path.join(test_path, folder)\n    for file in os.listdir(folder_path):\n        file_path = os.path.join(folder_path, file)\n        img = cv2.imread(file_path)\n        img = cv2.resize(img, (224,224))\n        img = preprocess_input(np.array([img]))  \n\n        predictions = model.predict(img)\n        real_label.append(folder)\n        predicted_class_index = np.argmax(predictions)\n        predicted_class.append(le.classes_[predicted_class_index])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:38:59.591898Z","iopub.execute_input":"2024-06-07T22:38:59.592215Z","iopub.status.idle":"2024-06-07T22:39:20.296723Z","shell.execute_reply.started":"2024-06-07T22:38:59.592175Z","shell.execute_reply":"2024-06-07T22:39:20.295626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_labels = np.array(real_label)\npredicted_classes = np.array(predicted_class)\n\naccuracy = accuracy_score(real_labels, predicted_classes)\nprecision = precision_score(real_labels, predicted_classes, average='weighted')\nrecall = recall_score(real_labels, predicted_classes, average='weighted')\nf1 = f1_score(real_labels, predicted_classes, average='weighted')\n\nprint(f\"\\nAccuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:43:13.993567Z","iopub.execute_input":"2024-06-07T22:43:13.994497Z","iopub.status.idle":"2024-06-07T22:43:14.011746Z","shell.execute_reply.started":"2024-06-07T22:43:13.994461Z","shell.execute_reply":"2024-06-07T22:43:14.010659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_labels = np.array(real_label)\npredicted_classes = np.array(predicted_class)\n\nconf_matrix = confusion_matrix(real_labels, predicted_classes)\n\nclass_names = [str(i) for i in range(len(conf_matrix))] \nprint(classification_report(real_labels, predicted_classes, target_names=class_names))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:43:14.013869Z","iopub.execute_input":"2024-06-07T22:43:14.014799Z","iopub.status.idle":"2024-06-07T22:43:14.033980Z","shell.execute_reply.started":"2024-06-07T22:43:14.014771Z","shell.execute_reply":"2024-06-07T22:43:14.033124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_matrix = confusion_matrix(real_label, predicted_class)\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:43:14.035105Z","iopub.execute_input":"2024-06-07T22:43:14.035456Z","iopub.status.idle":"2024-06-07T22:43:14.460131Z","shell.execute_reply.started":"2024-06-07T22:43:14.035422Z","shell.execute_reply":"2024-06-07T22:43:14.459280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert Model ke TFJS","metadata":{}},{"cell_type":"code","source":"!tensorflowjs_converter --input_format keras best_model_EfficientNetB0.h5 tfjs/model","metadata":{"execution":{"iopub.status.busy":"2024-06-07T22:43:14.462426Z","iopub.execute_input":"2024-06-07T22:43:14.462885Z","iopub.status.idle":"2024-06-07T22:43:21.016583Z","shell.execute_reply.started":"2024-06-07T22:43:14.462850Z","shell.execute_reply":"2024-06-07T22:43:21.015564Z"},"trusted":true},"execution_count":null,"outputs":[]}]}